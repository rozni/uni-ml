{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# for switching between GPU and CPU\n",
    "NO_GPU = False\n",
    "\n",
    "import os\n",
    "from os.path import exists\n",
    "if NO_GPU:\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import keras.layers as kl\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import scipy\n",
    "import skimage, skimage.draw, skimage.transform\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(*layers, verbose=False,\n",
    "               optimizer='adam', loss='categorical_crossentropy', metrics=['acc'],\n",
    "               compile_kwargs={}):\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    for layer in layers:\n",
    "        model.add(layer)\n",
    "        \n",
    "    if verbose:\n",
    "        print(\"Model summary:\")\n",
    "        model.summary()\n",
    "    \n",
    "    for kw in ('optimizer', 'loss', 'metrics'):\n",
    "        if not kw in compile_kwargs:\n",
    "            compile_kwargs[kw] = locals()[kw]\n",
    "    model.compile(**compile_kwargs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_history(history, figsize=(15,4), title='', columns=2, start_x_from=0):\n",
    "    \"\"\"Graphs a history for each key (combines validation and training keys into one plot).\n",
    "    \n",
    "    start_x_from=N skips the first N entries.\n",
    "    \n",
    "    History can be a whole training history class or just a dict.\"\"\"\n",
    "    \n",
    "    if hasattr(history, 'history'): # full history given\n",
    "        history = history.history   # only that history is enough\n",
    "        \n",
    "    assert hasattr(history, 'keys')\n",
    "    keys = [key for key in history.keys() if not key.startswith(\"val_\")]\n",
    "    assert keys # there is one at least\n",
    "    epochs = list(range(1,len(history[keys[0]])+1)) # all should have the same size list\n",
    "    \n",
    "    rows = np.ceil(len(keys)/columns).astype('int')\n",
    "    \n",
    "    fig=plt.figure(figsize=figsize)\n",
    "    f = plt.title(title)\n",
    "    f.axes.get_xaxis().set_visible(False)\n",
    "    f.axes.get_yaxis().set_visible(False)\n",
    "    \n",
    "    i = 1\n",
    "    for key in sorted(keys):\n",
    "        valkey = \"val_\" + key\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        i += 1\n",
    "        plt.plot(epochs[start_x_from:], history[key][start_x_from:], label=\"Training \" + key,\n",
    "                 marker='.', color='#00A287', linestyle='')\n",
    "        \n",
    "        late_avg = np.mean(history[key][(len(history[key]) * 90) // 100 : ])\n",
    "        plt.plot((epochs[start_x_from], epochs[-1]), (late_avg, late_avg),\n",
    "                 color=\"#74E600\", label='Mean {:.3f}'.format(late_avg))\n",
    "        if valkey in history:\n",
    "            plt.plot(epochs[start_x_from:], history[valkey][start_x_from:], label='Validation ' + key,\n",
    "                    marker='+', color='#DF004F', linestyle='')\n",
    "            \n",
    "            late_avg = np.mean(history[valkey][(len(history[valkey]) * 90) // 100 : ])\n",
    "            plt.plot((epochs[start_x_from], epochs[-1]), (late_avg, late_avg),\n",
    "                     color=\"#FF6700\", label='Mean {:.3f}'.format(late_avg))\n",
    "        plt.legend()\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_imgs(images, columns=9, figsize=(15,7), title=''):\n",
    "    \"\"\"Displays images in a grid\"\"\"\n",
    "    \n",
    "    fig=plt.figure(figsize=figsize)\n",
    "    f = plt.title(title)\n",
    "    \n",
    "    f.axes.get_xaxis().set_visible(False)\n",
    "    f.axes.get_yaxis().set_visible(False)\n",
    "    \n",
    "    rows = np.ceil(len(images)/columns).astype('int')\n",
    "    \n",
    "    for i in range(1, len(images)+1):\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        f = plt.imshow(images[i-1], cmap=plt.cm.binary)\n",
    "        f.axes.get_xaxis().set_visible(False)\n",
    "        f.axes.get_yaxis().set_visible(False)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_same_length(*args):\n",
    "    \"\"\"Returns True if all arguments have equal len(.)\"\"\"\n",
    "    return all(len(a) == len(args[0]) for a in args)\n",
    "\n",
    "def shuffle_together(*numpy_arrays):\n",
    "    \"\"\"Shuffles numpy arrays in unison, returns a tuple.\n",
    "    \n",
    "    (applies the same random permutation to all of them,\n",
    "    so they have to be the same length on axis=0)\"\"\"\n",
    "    \n",
    "    assert all_same_length(*numpy_arrays)\n",
    "    permut = np.random.permutation(len(numpy_arrays[0]))\n",
    "    return tuple(a[permut] for a in numpy_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_smoothen(img):\n",
    "    i = scipy.ndimage.filters.gaussian_filter(img, 0.16)\n",
    "    #i = scipy.ndimage.filters.uniform_filter(img)\n",
    "    #i = restoration.denoise_tv_chambolle(img)\n",
    "    return i * (i > 0.2)\n",
    "\n",
    "def feature_sobel(img):\n",
    "    return scipy.ndimage.filters.sobel(img)\n",
    "    \n",
    "def feature_remove_dust(img):\n",
    "    out_img = img.copy()\n",
    "    labeled_img, nobjs = scipy.ndimage.label(img)\n",
    "    if nobjs > 1: \n",
    "        label_count_pairs = zip(*np.unique(labeled_img, return_counts=1))\n",
    "        label_count_pairs = sorted(label_count_pairs, key=lambda x: x[1], reverse=1)\n",
    "        \n",
    "        mask = np.zeros(img.shape)\n",
    "        for i in range(nobjs):\n",
    "            label, count = label_count_pairs[i]\n",
    "            if i < 2 or count > 15:\n",
    "                mask += (labeled_img == label)\n",
    "        out_img *= mask\n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_autoscale(img):\n",
    "    img = img.copy()\n",
    "\n",
    "    while not any(img[   0]): img = img[1:]\n",
    "    while not any(img[  -1]): img = img[ :-1]\n",
    "    while not any(img[:, 0]): img = img[:,1:]\n",
    "    while not any(img[:,-1]): img = img[:, :-1]\n",
    "\n",
    "    return skimage.transform.resize(img, (28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_arr(arr):\n",
    "    return arr / np.max(arr)\n",
    "\n",
    "def feature_histogram_vert(img):\n",
    "    return normalize_arr(np.apply_along_axis(sum, 0, img))\n",
    "\n",
    "def feature_histogram_horiz(img):\n",
    "    return normalize_arr(np.apply_along_axis(sum, 1, img))\n",
    "\n",
    "EDGES = []\n",
    "EDGES.extend([(i,  0) for i in range(13, -1, -1)])\n",
    "EDGES.extend([(0 , i) for i in range(28)])\n",
    "EDGES.extend([(i, 27) for i in range(28)])\n",
    "EDGES.extend([(27, i) for i in range(27, -1, -1)])\n",
    "EDGES.extend([(i,  0) for i in range(27, 13, -1)])\n",
    "MIDDLES = tuple((13 + c0 // 14, 13 + c1 // 14) for c0, c1 in EDGES)\n",
    "LINES = tuple(map(lambda m, e: skimage.draw.line_aa(*m,*e), MIDDLES, EDGES))\n",
    "\n",
    "def feature_histogram_circ(img):\n",
    "    sum_point = lambda r,c,v: v*img[r,c]\n",
    "    sum_line = lambda line: sum(map(sum_point, *line))\n",
    "    return normalize_arr(np.array(tuple(map(sum_line, LINES))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (-1, 28, 28, 1)\n",
    "VERBOSE=True\n",
    "\n",
    "BS = 500\n",
    "EPOCHS=50\n",
    "GEN_KWARGS = {} #dict(samplewise_center=True, samplewise_std_normalization=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000000 images belonging to 10 classes.\n",
      "Found 100000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "#### Import the dataset & apply transformations\n",
    "from urllib.request import urlretrieve\n",
    "filename, headers = urlretrieve(\n",
    "    'https://github.com/Avatust/my-mnist-digits/raw/master/data/digits.npz')\n",
    "\n",
    "with np.load(filename) as data:\n",
    "    x_test = data['input_data']\n",
    "    y_test = data['target_data']\n",
    "    \n",
    "y_test =  keras.utils.to_categorical(y_test)\n",
    "x_test =  x_test.astype('float32') / 255.0\n",
    "x_test_no_dust = np.array(\n",
    "    [\n",
    "        scipy.ndimage.grey_dilation(\n",
    "            feature_remove_dust(feature_smoothen(x)),\n",
    "            size=[2,2])\n",
    "        for x in x_test\n",
    "    ])\n",
    "x_test_no_dust_autoscaled = np.array([feature_autoscale(x) for x in x_test_no_dust])\n",
    "    \n",
    "IMG_DIR_BASE = 'images_from_flow/autoscaled_augmented'\n",
    "if exists(IMG_DIR_BASE):\n",
    "    makeflow = lambda subdir: ImageDataGenerator(rescale=1.0/255.0).flow_from_directory(\n",
    "        os.path.join(IMG_DIR_BASE, subdir),\n",
    "        target_size=(28,28),\n",
    "        color_mode='grayscale',\n",
    "        class_mode='categorical',\n",
    "        batch_size=BS,\n",
    "    )\n",
    "    flow_train_data = makeflow('train')\n",
    "    flow_valid_data = makeflow('valid')\n",
    "    \n",
    "else:\n",
    "    (x_train, y_train), (x_valid, y_valid) = keras.datasets\\\n",
    "                                            .mnist.load_data()\n",
    "\n",
    "    y_train = keras.utils.to_categorical(y_train)\n",
    "    y_valid = keras.utils.to_categorical(y_valid)\n",
    "\n",
    "    x_train = x_train.astype('float32') / 255.0\n",
    "    x_valid = x_valid.astype('float32') / 255.0\n",
    "\n",
    "    preprocess = lambda x: feature_remove_dust(feature_smoothen(x))\n",
    "    x_train_no_dust = np.array([preprocess(x) for x in x_train]) \n",
    "    x_valid_no_dust = np.array([preprocess(x) for x in x_valid]) \n",
    "\n",
    "    scale = lambda x: feature_autoscale(x.reshape(28, 28)).reshape(28, 28, 1)\n",
    "    data_gen = ImageDataGenerator(rotation_range=20,\n",
    "                                   width_shift_range=0.13, height_shift_range=0.13,\n",
    "                                   shear_range=0.2, zoom_range=0.1,\n",
    "                                   fill_mode='constant', cval=0.0,\n",
    "                                   data_format='channels_last', preprocessing_function=scale)\n",
    "    flow_train_data = data_gen.flow(x_train_no_dust.reshape(INPUT_SHAPE), y_train, batch_size=BS)\n",
    "    flow_valid_data = data_gen.flow(x_valid_no_dust.reshape(INPUT_SHAPE), y_valid, batch_size=BS)\n",
    "    \n",
    "#x_train_no_dust_sobel = np.array(tuple(map(feature_sobel, x_train_no_dust)))\n",
    "#x_valid_no_dust_sobel = np.array(tuple(map(feature_sobel, x_valid_no_dust)))\n",
    "#x_test_no_dust_sobel = np.array(tuple(map(feature_sobel, x_test_no_dust)))\n",
    "#\n",
    "#x_train_no_dust_autoscaled = np.array(tuple(map(feature_autoscale, x_train_no_dust)))\n",
    "#x_valid_no_dust_autoscaled = np.array(tuple(map(feature_autoscale, x_valid_no_dust)))\n",
    "#x_test_no_dust_autoscaled = np.array(tuple(map(feature_autoscale, x_test_no_dust)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_histogram(img):\n",
    "    return np.concatenate((feature_histogram_horiz(img), \n",
    "                           feature_histogram_vert(img),\n",
    "                           feature_histogram_circ(img)))\n",
    "\n",
    "def transform_to_histograms(img_array):\n",
    "    return np.array([get_histogram(img) for img in img_array])\n",
    "\n",
    "#x_train_histograms = transform_to_histograms(x_train_no_dust_autoscaled)\n",
    "#x_valid_histograms = transform_to_histograms(x_valid_no_dust_autoscaled)\n",
    "x_test_histograms =  transform_to_histograms(x_test_no_dust_autoscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_histogram_flow(data_flow):\n",
    "    while True:\n",
    "        inputs, targets = next(data_flow)\n",
    "        yield np.array([get_histogram(i.reshape(28,28)) for i in inputs]), targets\n",
    "    \n",
    "flow_hist_train_data = make_histogram_flow(flow_train_data)\n",
    "flow_hist_valid_data = make_histogram_flow(flow_valid_data)\n",
    "#test_data_flow_hist =  make_histogram_flow(test_data_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCAv6/6D7MCZKB6xLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcb953bdef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = next(flow_hist_train_data)[0][0]\n",
    "plt.plot(i[:28])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_imgs(train_data_flow_hist.next()[0][:45].reshape(45, 28,28))\n",
    "show_imgs(test_data_flow.next()[0][:45].reshape(45, 28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = train_data_flow.next()\n",
    "np.savez('images_from_flow/autoscaled_augmented_train', targets=d[0].reshape(-1, ) \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_imgs([random.choice(x_test).reshape(28,28) for i in range(45)])\n",
    "show_imgs([random.choice(x_train).reshape(28,28) for i in range(45)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "examples = [random.choice(x_train).reshape(28,28) for i in range(45)]\n",
    "show_imgs(examples, title='No features')\n",
    "show_imgs([feature_remove_dust(feature_smoothen(e)) for e in examples], title=\"'Dust' removal and smoothening\")\n",
    "show_imgs([feature_sobel(feature_remove_dust(feature_smoothen(e))) for e in examples], title=\"Sobelizing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    im = random.choice(x_train)\n",
    "    im = feature_smoothen(im)\n",
    "    im = feature_remove_dust(im)\n",
    "    im = feature_autoscale(im)\n",
    "    \n",
    "    plt.subplot(311)\n",
    "    plt.plot(feature_histogram_vert(im), label='Vertical histogram')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(312)\n",
    "    plt.plot(feature_histogram_horiz(im), label='Horizontal histogram')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(313)\n",
    "    plt.plot(feature_histogram_circ(im), label='I would call it a circular histogram')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(im)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# baseline (validation accuracy about 0.90)\n",
    "# its siblings were reaching accuracy up to 0.92 (and blazingly fast to train)\n",
    "model_simple = build_model(\n",
    "    kl.InputLayer((28,28,1)),\n",
    "    \n",
    "    kl.Conv2D(filters=8, kernel_size=3, activation='relu', padding='same'),\n",
    "    kl.Dropout(0.2),\n",
    "    kl.MaxPool2D(pool_size=2, strides=2),\n",
    "    \n",
    "    kl.Flatten(),\n",
    "    \n",
    "    kl.Dropout(0.2),\n",
    "    kl.Dense(units=64, activation='relu'),\n",
    "    kl.Dense(units=10, activation='softmax'),\n",
    "    \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "hist_simple = model_simple.fit(x_train_no_dust.reshape(INPUT_SHAPE), y_train,\n",
    "                               validation_data=(x_valid_no_dust.reshape(INPUT_SHAPE), y_valid),\n",
    "                               epochs=EPOCHS, batch_size=BS, verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Eval:', model_simple.evaluate(x_test_no_dust.reshape(INPUT_SHAPE), y_test, verbose=0))\n",
    "\n",
    "plot_history(hist_simple, start_x_from=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# baseline (validation accuracy about 0.90)\n",
    "# its siblings were reaching accuracy up to 0.92 (and blazingly fast to train)\n",
    "model_simple_autoscale = build_model(\n",
    "    kl.InputLayer((28,28,1)),\n",
    "    \n",
    "    kl.Conv2D(filters=8, kernel_size=3, activation='relu', padding='same'),\n",
    "    kl.Dropout(0.2),\n",
    "    kl.MaxPool2D(pool_size=2, strides=2),\n",
    "    \n",
    "    kl.Flatten(),\n",
    "    \n",
    "    kl.Dropout(0.2),\n",
    "    kl.Dense(units=64, activation='relu'),\n",
    "    kl.Dense(units=10, activation='softmax'),\n",
    "    \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "hist_simple_autoscale = model_simple_autoscale.fit(x_train_no_dust_autoscaled.reshape(INPUT_SHAPE), y_train,\n",
    "                               validation_data=(x_test_no_dust_autoscaled.reshape(INPUT_SHAPE), y_test),\n",
    "                               epochs=EPOCHS, batch_size=BS, verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Eval:', model_simple_autoscale.evaluate(x_test_no_dust_autoscaled.reshape(INPUT_SHAPE), y_test, verbose=0))\n",
    "\n",
    "plot_history(hist_simple_autoscale, start_x_from=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# baseline (validation accuracy about 0.90)\n",
    "# its siblings were reaching accuracy up to 0.92 (and blazingly fast to train)\n",
    "model_simple_sobel = build_model(\n",
    "    kl.InputLayer((28,28,1)),\n",
    "    \n",
    "    kl.Conv2D(filters=8, kernel_size=3, activation='relu', padding='same'),\n",
    "    kl.Dropout(0.2),\n",
    "    kl.MaxPool2D(pool_size=2, strides=2),\n",
    "    \n",
    "    kl.Flatten(),\n",
    "    \n",
    "    kl.Dropout(0.2),\n",
    "    kl.Dense(units=64, activation='relu'),\n",
    "    kl.Dense(units=10, activation='softmax'),\n",
    "    \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "hist_simple_sobel = model_simple_sobel.fit(x_train_no_dust_sobel.reshape(INPUT_SHAPE), y_train,\n",
    "                               validation_data=(x_test_no_dust_sobel.reshape(INPUT_SHAPE), y_test),\n",
    "                               epochs=EPOCHS, batch_size=BS, verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Eval:', model_simple_sobel.evaluate(x_test_no_dust_sobel.reshape(INPUT_SHAPE), y_test, verbose=0))\n",
    "\n",
    "plot_history(hist_simple_sobel, start_x_from=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lentil_reg = build_model(\n",
    "    kl.InputLayer((28,28,1)),\n",
    "\n",
    "    kl.Conv2D(filters=20, kernel_size=5, padding='same', activation='relu'),\n",
    "    kl.Conv2D(filters=40, kernel_size=3, padding='same', activation='relu'),\n",
    "    kl.Dropout(0.1),\n",
    "    kl.MaxPool2D(pool_size=2, strides=2),\n",
    "\n",
    "\n",
    "    kl.Conv2D(filters=50, kernel_size=5, padding='same', activation='relu'),\n",
    "    kl.Dropout(0.1),\n",
    "    kl.MaxPool2D(pool_size=2, strides=2),\n",
    "\n",
    "    kl.Flatten(),\n",
    "\n",
    "    kl.Dropout(0.1),\n",
    "    kl.Dense(units=200, activation='relu'),\n",
    "    kl.Dense(units=80, activation='relu'),\n",
    "    kl.Dense(units=10, activation='softmax'),\n",
    "    \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "hist_lentil_reg = model_lentil_reg.fit_generator(generator=train_data_flow,\n",
    "                                    validation_data=test_data_flow,\n",
    "                                    steps_per_epoch=len(x_train) // BS,\n",
    "                                    epochs=40, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Eval:', model_lentil_reg.evaluate_generator(test_data_flow))\n",
    "\n",
    "plot_history(hist_lentil_reg, start_x_from=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_just_dense = build_model(\n",
    "    kl.InputLayer((168,)),\n",
    "    \n",
    "    kl.Dense(units=170, activation='elu'),\n",
    "    kl.Dropout(0.2),\n",
    "    kl.Dense(units=120, activation='elu'),\n",
    "    kl.Dropout(0.1),\n",
    "    kl.Dense(units=80, activation='elu'),\n",
    "    kl.Dropout(0.1),\n",
    "    kl.Dense(units=80, activation='elu'),\n",
    "    kl.Dense(units=10, activation='softmax'),\n",
    "    \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "#hist_just_dense = model_just_dense.fit(x_train_histograms, y_train,\n",
    "#                                       validation_data=(x_test_histograms, y_test),\n",
    "#                                       epochs=300, batch_size=2000, verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_just_dense = model_just_dense.fit_generator(generator=train_data_flow_hist,\n",
    "                                    validation_data=(x_test_histograms, y_test),\n",
    "                                    steps_per_epoch=len(x_train) // BS,\n",
    "                                    epochs=40, verbose=1)\n",
    "\n",
    "print('Eval:', model_just_dense.evaluate(x_test_histograms, y_test))\n",
    "\n",
    "\n",
    "plot_history(hist_just_dense, start_x_from=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_just_dense = build_model(\n",
    "    kl.InputLayer((168,1)),\n",
    "    kl.Flatten(),\n",
    "    \n",
    "    kl.Dense(units=168, activation='relu', kernel_constraint=keras.constraints.max_norm(3)),\n",
    "    kl.Dropout(0.1),\n",
    "    kl.Dense(units=168, activation='relu', kernel_constraint=keras.constraints.max_norm(3)),\n",
    "    kl.Dense(units=100, activation='relu', kernel_constraint=keras.constraints.max_norm(3)),\n",
    "    kl.Dropout(0.1),\n",
    "    kl.Dense(units=60, activation='relu', kernel_constraint=keras.constraints.max_norm(3)),\n",
    "    kl.Dense(units=10, activation='softmax'),\n",
    "    \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nexttrain_data_flow_hist)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist_just_dense = model_just_dense.fit(x_train_histograms.reshape(-1, 168, 1), y_train,\n",
    "                                       validation_data=(x_test_histograms.reshape(-1, 168, 1), y_test),\n",
    "                                       epochs=500, batch_size=20000, verbose=VERBOSE)\n",
    "print('Eval:', model_just_dense.evaluate(x_test_histograms.reshape(-1, 168, 1), y_test))\n",
    "\n",
    "\n",
    "plot_history(hist_just_dense, start_x_from=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
