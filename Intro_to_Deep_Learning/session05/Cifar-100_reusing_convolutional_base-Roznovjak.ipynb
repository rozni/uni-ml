{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did not pay much attention to the Cifar-10 convnet and was reaching accuracy of about 65%. That's why I did not want to use it as my base and instead I decided to try to use the models packed with Keras - that immediately lead me to the problem that the resolution of the images in Cifar-100 is too small. After looking at the architectures of the models I just decided to use the VGG16 as it is the most shallow one and cuts down the dimensions the least.\n",
    "\n",
    "To cope with the problem of too small images I was trying to change the way of pooling (padding and strides so that the first two dimensions of the input would stay the same) and/or cutting the last layers off. The approach with which I have achieved the best results was to only adjust the first two pooling layers (I did not want to change more as that would inflate the size of the output tensors and perhaps without a tangible benefit) - this also fits with my hypothesis that doing this near the beginning still retains a lot of information from the images, however, in latter layers the information gets too mangled and doing a max-pool on 1x1 does not give sense...\n",
    "\n",
    "I was using the test data as validation data to tweak the hyperparemeters - but only on filtered pictures containing only 3 categories (bears, otters, wolves - I wanted to know how well it would do in a forest :) ). In the end I tried to evaluate it (no longer changing the model) also on different categories - which did better (probably because the categories had much more prominent differences) - the first time I tried to evaluate it on different categories the final accuracy was around 99% (and using less epochs), rerunning this notebook (and thus selecting different evaluation categories as I choose them at random) gave the accuracy of 95%, on the original categories 89% and it looks like I could have been training a bit longer.\n",
    "\n",
    "Overall, I am pretty happy with the results as the resolution is really low and I presume the convolutional base would be able to extract better features having higher resolution... (Actually, I wonder a bit how come it performed so well as ImageNet has much more subtle low-level features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e89942445776>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# for switching between GPU and CPU\n",
    "NO_GPU = False\n",
    "\n",
    "if NO_GPU:\n",
    "    import os\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "    \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import keras.layers as kl\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.datasets import cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(*layers, verbose=False,\n",
    "               optimizer='adam', loss='categorical_crossentropy', metrics=['acc'],\n",
    "               compile_kwargs={}):\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    for layer in layers:\n",
    "        model.add(layer)\n",
    "        \n",
    "    if verbose:\n",
    "        print(\"Model summary:\")\n",
    "        model.summary()\n",
    "    \n",
    "    for kw in ('optimizer', 'loss', 'metrics'):\n",
    "        if not kw in compile_kwargs:\n",
    "            compile_kwargs[kw] = locals()[kw]\n",
    "    model.compile(**compile_kwargs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, figsize=(15,4), title='', columns=2, start_x_from=0):\n",
    "    \"\"\"Graphs a history for each key (combines validation and training keys into one plot).\n",
    "    \n",
    "    start_x_from=N skips the first N entries.\n",
    "    \n",
    "    History can be a whole training history class or just a dict.\"\"\"\n",
    "    \n",
    "    if hasattr(history, 'history'): # full history given\n",
    "        history = history.history   # only that history is enough\n",
    "        \n",
    "    assert hasattr(history, 'keys')\n",
    "    keys = [key for key in history.keys() if not key.startswith(\"val_\")]\n",
    "    assert keys # there is one at least\n",
    "    epochs = list(range(1,len(history[keys[0]])+1)) # all should have the same size list\n",
    "    \n",
    "    rows = np.ceil(len(keys)/columns).astype('int')\n",
    "    \n",
    "    fig=plt.figure(figsize=figsize)\n",
    "    f = plt.title(title)\n",
    "    f.axes.get_xaxis().set_visible(False)\n",
    "    f.axes.get_yaxis().set_visible(False)\n",
    "    \n",
    "    i = 1\n",
    "    for key in sorted(keys):\n",
    "        valkey = \"val_\" + key\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        i += 1\n",
    "        plt.plot(epochs[start_x_from:], history[key][start_x_from:], label=\"Training \" + key,\n",
    "                 marker='.', color='#00A287', linestyle='')\n",
    "        \n",
    "        late_avg = np.mean(history[key][(len(history[key]) * 90) // 100 : ])\n",
    "        plt.plot((epochs[start_x_from], epochs[-1]), (late_avg, late_avg),\n",
    "                 color=\"#74E600\", label='Mean {:.3f}'.format(late_avg))\n",
    "        if valkey in history:\n",
    "            plt.plot(epochs[start_x_from:], history[valkey][start_x_from:], label='Validation ' + key,\n",
    "                    marker='+', color='#DF004F', linestyle='')\n",
    "            \n",
    "            late_avg = np.mean(history[valkey][(len(history[valkey]) * 90) // 100 : ])\n",
    "            plt.plot((epochs[start_x_from], epochs[-1]), (late_avg, late_avg),\n",
    "                     color=\"#FF6700\", label='Mean {:.3f}'.format(late_avg))\n",
    "        plt.legend()\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_imgs(images, columns=9, figsize=(15,7), title=''):\n",
    "    \"\"\"Displays images in a grid\"\"\"\n",
    "    \n",
    "    fig=plt.figure(figsize=figsize)\n",
    "    f = plt.title(title)\n",
    "    \n",
    "    f.axes.get_xaxis().set_visible(False)\n",
    "    f.axes.get_yaxis().set_visible(False)\n",
    "    \n",
    "    rows = np.ceil(len(images)/columns).astype('int')\n",
    "    \n",
    "    for i in range(1, len(images)+1):\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        f = plt.imshow(images[i-1], cmap=plt.cm.binary)\n",
    "        f.axes.get_xaxis().set_visible(False)\n",
    "        f.axes.get_yaxis().set_visible(False)\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "def show_random_imgs(images, title=''):\n",
    "    indices = np.random.choice(range(len(images)), 45, replace=0)\n",
    "    show_imgs(images[indices], title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_categories(input_set, target_set, categories):\n",
    "    categories = set(categories)\n",
    "    \n",
    "    indices = np.apply_along_axis(\n",
    "        lambda category: category[0] in categories,\n",
    "        axis=-1,\n",
    "        arr=target_set)\n",
    "    \n",
    "    recatg_map = dict(zip(categories, range(len(categories))))\n",
    "    \n",
    "    transformed_target_categories = np.apply_along_axis(\n",
    "        lambda category: recatg_map[category[0]],\n",
    "        axis=-1,\n",
    "        arr=target_set[indices])\n",
    "    \n",
    "    return input_set[indices], transformed_target_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "# normalize\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_random_imgs(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {3,55,97} # bears, otters, wolves\n",
    "\n",
    "xf_train, yf_train = filter_categories(x_train, y_train, categories)\n",
    "xf_test, yf_test = filter_categories(x_test, y_test, categories)\n",
    "\n",
    "# one-hot potato\n",
    "yf_train = keras.utils.to_categorical(yf_train)\n",
    "yf_test = keras.utils.to_categorical(yf_test)\n",
    "assert yf_train.shape[1] == len(categories)\n",
    "\n",
    "show_random_imgs(xf_train, \"Lovely, aren't they?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locomotive_datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator = locomotive_datagen.flow(\n",
    "    xf_train,\n",
    "    yf_train,\n",
    "    batch_size=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xf_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import VGG16 as ConvBase\n",
    "\n",
    "conv_base = ConvBase(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=None)\n",
    "\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in conv_base.layers:\n",
    "    if 'pool' in l.name and ('1' in l.name or '2' in l.name):\n",
    "        l.padding='same'\n",
    "        l.strides=(1,1)\n",
    "        \n",
    "conv_base.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    kl.InputLayer(xf_train.shape[1:]),\n",
    "    conv_base,\n",
    "    kl.Flatten(),\n",
    "    kl.Dropout(.35),\n",
    "    kl.Dense(256, activation='relu'),\n",
    "    kl.Dropout(.3),\n",
    "    kl.Dense(128, activation='relu'),\n",
    "    kl.Dense(3, activation='softmax'),\n",
    "    verbose=True,\n",
    "    optimizer=keras.optimizers.RMSprop(lr=1e-4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=30,\n",
    "    epochs=80,\n",
    "    validation_data=(xf_test,yf_test),\n",
    "    workers=4,\n",
    "    use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "for l in conv_base.layers[:-4]: l.trainable=False\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=keras.optimizers.RMSprop(lr=1e-5),\n",
    "    metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=30,\n",
    "    epochs=160,\n",
    "    validation_data=(xf_test,yf_test),\n",
    "    workers=4,\n",
    "    use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And again...\n",
    "Let's see how it performs on some random categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = set(np.random.choice(range(100), 3, False))\n",
    "print(categories)\n",
    "\n",
    "xf_train, yf_train = filter_categories(x_train, y_train, categories)\n",
    "xf_test, yf_test = filter_categories(x_test, y_test, categories)\n",
    "\n",
    "# one-hot potato\n",
    "yf_train = keras.utils.to_categorical(yf_train)\n",
    "yf_test = keras.utils.to_categorical(yf_test)\n",
    "assert yf_train.shape[1] == len(categories)\n",
    "\n",
    "show_random_imgs(xf_train, \"Lovely, aren't they?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locomotive_datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator = locomotive_datagen.flow(\n",
    "    xf_train,\n",
    "    yf_train,\n",
    "    batch_size=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import VGG16 as ConvBase\n",
    "\n",
    "conv_base = ConvBase(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=None)\n",
    "\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in conv_base.layers:\n",
    "    if 'pool' in l.name and ('1' in l.name or '2' in l.name):\n",
    "        l.padding='same'\n",
    "        l.strides=(1,1)\n",
    "        \n",
    "conv_base.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    kl.InputLayer(xf_train.shape[1:]),\n",
    "    conv_base,\n",
    "    kl.Flatten(),\n",
    "    kl.Dropout(.3),\n",
    "    kl.Dense(256, activation='relu'),\n",
    "    kl.Dropout(.3),\n",
    "    kl.Dense(128, activation='relu'),\n",
    "    kl.Dense(3, activation='softmax'),\n",
    "    verbose=True,\n",
    "    optimizer=keras.optimizers.RMSprop(lr=1e-4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=30,\n",
    "    epochs=50,\n",
    "    validation_data=(xf_test,yf_test),\n",
    "    workers=4,\n",
    "    use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "for l in conv_base.layers[:-4]: l.trainable=False\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=keras.optimizers.RMSprop(lr=1e-5),\n",
    "    metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=30,\n",
    "    epochs=100,\n",
    "    validation_data=(xf_test,yf_test),\n",
    "    workers=4,\n",
    "    use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(hist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
