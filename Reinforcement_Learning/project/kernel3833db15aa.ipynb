{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numba\n",
    "from numba import cuda\n",
    "from numba.cuda.random import create_xoroshiro128p_states, xoroshiro128p_uniform_float32\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit(device=True, inline=True)\n",
    "def cuda_is_sorted(arr, length: 'arr.size'):\n",
    "    idx = 0\n",
    "    sort_stop = length - 1\n",
    "    # while-loop was much faster than a for-loop\n",
    "    while idx < sort_stop:\n",
    "        if arr[idx] > arr[idx+1]:\n",
    "            return False\n",
    "        idx += 1\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit(device=True, inline=True)\n",
    "def cuda_random_index(\n",
    "    rng_states: 'pre-initialized random seeds for every thread',\n",
    "    rng_idx: 'globally unique thread ID',\n",
    "    max_idx: 'highest index (exclusive)'\n",
    ") -> 'integer [0, max_idx)':\n",
    "    rand = xoroshiro128p_uniform_float32(rng_states, rng_idx)\n",
    "    # int() floors the result\n",
    "    return int(max_idx*rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The expected number of swaps grows more than fast:\n",
    "# n! + 2(n-2)! + o((n-2)!) for n -> inf\n",
    "# as shown by Flatto/Odlyzko/Wales in\n",
    "# http://www.dtc.umn.edu/~odlyzko/doc/arch/random.shuffles.pdf\n",
    "# Therefore, we will be able to analyze nothing but\n",
    "# small arrays\n",
    "MAX_ARR_SIZE = 16\n",
    "\n",
    "@cuda.jit\n",
    "def cuda_expectation(rng_states, arr, out):\n",
    "    # allocate L1 cache\n",
    "    local_arr = cuda.local.array(MAX_ARR_SIZE, dtype=numba.int32)\n",
    "    \n",
    "    # initialize the local memory\n",
    "    length = arr.size\n",
    "    for idx in range(length):\n",
    "        local_arr[idx] = arr[idx]\n",
    "        \n",
    "    \n",
    "    # globally unique index/ID\n",
    "    thread_id = cuda.grid(1)\n",
    "    \n",
    "    swap_count = 0\n",
    "    while not cuda_is_sorted(local_arr, length):\n",
    "        \n",
    "        # choose a random pair\n",
    "        i = cuda_random_index(rng_states, thread_id, length)\n",
    "        j = cuda_random_index(rng_states, thread_id, length)\n",
    "        while i==j:\n",
    "            j = cuda_random_index(rng_states, thread_id, length)\n",
    "            \n",
    "        # swap the pair\n",
    "        temp = local_arr[i]\n",
    "        local_arr[i] = local_arr[j]\n",
    "        local_arr[j] = temp\n",
    "        \n",
    "        swap_count += 1\n",
    "        \n",
    "    # done with this thread\n",
    "    out[thread_id] = swap_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectation(\n",
    "    arr: 'Numpy 1D int32 array of at most MAX_ARR_SIZE elements',\n",
    "    runs: 'number of iterations or a tuple of GPU block and threads',\n",
    "    seed: 'random generator seed, default is reuse or current time' = None,\n",
    "):\n",
    "    assert (\n",
    "        arr.ndim == 1 and\n",
    "        arr.size < MAX_ARR_SIZE and\n",
    "        arr.dtype == np.int32\n",
    "    )\n",
    "\n",
    "    # calc grid, blocks, threads per block\n",
    "    if type(runs) == int:\n",
    "        grid_size = runs\n",
    "        threads = 32\n",
    "        blocks = (grid_size + threads - 1)//threads\n",
    "    else:\n",
    "        blocks, threads = runs\n",
    "        grid_size = blocks*threads\n",
    "        \n",
    "    # get random generator states\n",
    "    if seed is None:\n",
    "        prev_grid_size = None\n",
    "        prev_rng_states = getattr(expectation, 'prev_rng_states', None)\n",
    "        try:\n",
    "            prev_grid_size = prev_rng_states.size\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        if grid_size != prev_grid_size:\n",
    "            seed = int(1000*time.time())\n",
    "            rng_states = create_xoroshiro128p_states(grid_size, seed=seed)\n",
    "        else:\n",
    "            rng_states = prev_rng_states\n",
    "    else:\n",
    "        rng_states = create_xoroshiro128p_states(grid_size, seed=seed)\n",
    "    expectation.prev_rng_states = rng_states\n",
    "    \n",
    "    # the good stuff\n",
    "#     cuda_results = cuda.device_array(grid_size, dtype=np.int32)\n",
    "#     cuda_expectation(rng_states, arr, cuda_results)\n",
    "#     results = cuda_results.to_host()\n",
    "    results = np.empty(grid_size, dtype=np.int32)\n",
    "    cuda_expectation(rng_states, arr, results)\n",
    "    \n",
    "    return results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.randint(0, 6, 10, dtype=np.int32)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expectation(arr, 2**15, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit expectation(arr, 2**15, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat May 25 07:27:53 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 410.104      Driver Version: 410.104      CUDA Version: 10.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla P100-PCIE...  On   | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   43C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --proc nvpid --bg --out nvsmi\n",
    "nvidia-smi --query-gpu=index,utilization.gpu,utilization.memory,memory.total,memory.used --format=csv -l 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvpid.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while nvpid.poll() is None: print(nvsmi.readline().decode().strip())\n",
    "\n",
    "print(nvsmi.read().decode())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
