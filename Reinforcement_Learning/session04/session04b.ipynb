{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TX00DQ05-3001 Exercises 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld:\n",
    "    \"\"\"\n",
    "    A basic grid world environment (based on Sutton & Barto example 4.1)\n",
    "    without any blows and whistles or argument validation...\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, rows, columns, terminal_states: 'Iterable[(row, col)]'):\n",
    "        self._rows = rows\n",
    "        self._cols = columns\n",
    "        self._term_states = terminal_states\n",
    "    \n",
    "    ## a friendly environment's methods\n",
    "    \n",
    "    def get_init_state(self) -> 'state':\n",
    "        state = self._term_states[0]\n",
    "        while self.is_terminal(state):\n",
    "            r = np.random.randint(self._rows)\n",
    "            c = np.random.randint(self._rows)\n",
    "            state = r, c\n",
    "        return state\n",
    "    \n",
    "    def is_terminal(self, state) -> bool:\n",
    "        return state in self._term_states\n",
    "    \n",
    "    def get_actions(self, state=None) -> 'Iterable[action]':\n",
    "        return self._action.ACTIONS\n",
    "    \n",
    "    def take_action(self, state, action) -> 'new_state, reward':\n",
    "        r, c = state\n",
    "        rx, cx = action\n",
    "        r = np.clip(r + rx, 0, self._rows-1)\n",
    "        c = np.clip(c + cx, 0, self._cols-1)\n",
    "        new_state = (r, c)\n",
    "        reward = -1\n",
    "        return new_state, reward\n",
    "    \n",
    "    \n",
    "    ## making life easier / a friendlier environment\n",
    "    \n",
    "    def get_number_of_states(self) -> int:\n",
    "        return self._rows*self._cols\n",
    "    \n",
    "    def get_number_of_actions(self) -> int:\n",
    "        return len(self._action.ACTIONS)\n",
    "    \n",
    "    def get_state_index(self, state) -> int:\n",
    "        return state[0]*self._cols + state[1] # [[0, 1], [2, 3]]\n",
    "    \n",
    "    def get_action_index(self, action) -> int:\n",
    "        return self._action.ACTIONS.index(action)\n",
    "        \n",
    "    def which_state(self, state_index: int) -> 'state':\n",
    "        return divmod(state_index, self._cols)\n",
    "        \n",
    "    def which_action(self, action_index: int) -> 'action':\n",
    "        return self._action.ACTIONS[action_index]\n",
    "    \n",
    "    def action_label(self, a: 'int or action') -> 'pretty arrow':\n",
    "        if type(a) is tuple:\n",
    "            a = self.get_action_index(a)\n",
    "        return self._action.ACTION_LABELS[a]\n",
    "    \n",
    "    \n",
    "    class _action:\n",
    "        UP   = np.array((-1, 0))\n",
    "        DOWN = np.array((1, 0))\n",
    "        LEFT = np.array((0, -1))\n",
    "        RIGHT= np.array((0, 1))\n",
    "\n",
    "        ACTIONS = (UP, DOWN, LEFT, RIGHT)\n",
    "        ACTION_LABELS = ('↑', '↓', '←', '→')\n",
    "        N_ACTIONS = len(ACTIONS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GW4p1 = GridWorld(4,4,((0, 0), (3, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: TD(0) value function estimation\n",
    "\n",
    "Implement value function estimation for Sutton & Barto example 4.1 with TD(0) algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TD0(\n",
    "    gw: GridWorld,\n",
    "    maxiters: 'number of iterations, no early stopping',\n",
    "    alpha_schedule: 'Callable(episode_num, previous_alpha?) -> alpha',\n",
    "    gamma: 'constant discount factor',\n",
    ") -> 'state-value matrix':\n",
    "    \n",
    "    V = defaultdict(lambda: 0)\n",
    "    \n",
    "    alpha = None\n",
    "    for i in range(maxiters):\n",
    "\n",
    "        alpha = alpha_schedule(i, alpha)\n",
    "        state = gw.get_init_state()\n",
    "        while not gw.is_terminal(state):\n",
    "            action = random.choice(gw.get_actions(state))\n",
    "            new_state, reward = gw.take_action(state, action)\n",
    "            V[state] += alpha*(reward + gamma*V[new_state] - V[state])\n",
    "            state = new_state\n",
    "\n",
    "    return V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constant_alpha_schedule_factory(alpha):\n",
    "    return lambda episode, prev_alpha: alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00\t-13.04\t-17.55\t-20.20\t\n",
      "-13.88\t-17.33\t-19.28\t-19.49\t\n",
      "-21.08\t-20.54\t-18.24\t-13.62\t\n",
      "-22.52\t-20.61\t-16.09\t  0.00\t\n"
     ]
    }
   ],
   "source": [
    "v = TD0(\n",
    "    GW4p1,\n",
    "    maxiters=10000,\n",
    "    alpha_schedule=constant_alpha_schedule_factory(0.05),\n",
    "    gamma=1\n",
    ")\n",
    "    \n",
    "for row in range(4):\n",
    "    for col in range(4):\n",
    "        l = v[(row, col)]\n",
    "        s = f'{l:6.2f}'\n",
    "        print(s, end='\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Implement TD(0) control \n",
    "\n",
    "Solve Sutton & Barto example 4.1 with TD(0) control (Sarsa) algorithm. Apply the algorithm to the windy world of Sutton & Barto example 6.5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sarsa(\n",
    "    gw: GridWorld,\n",
    "    maxiters: 'number of iterations, no early stopping',\n",
    "    policy: 'Callable(q, state_index, eps) -> action_index',\n",
    "    eps_schedule: 'Callable(iteration, previous_eps?) -> eps',\n",
    "    alpha_schedule: 'Callable(episode_num, previous_alpha?) -> alpha',\n",
    "    gamma: 'constant discount factor',\n",
    ") -> 'action-value table - 2D array: state_indices×action_indices':\n",
    "    \n",
    "    Q = np.zeros((gw.get_number_of_states(), gw.get_number_of_actions()))\n",
    "    eps = None\n",
    "    alpha = None\n",
    "    \n",
    "    for i in range(1, maxiters+1):\n",
    "        eps = eps_schedule(i, eps)\n",
    "        alpha = alpha_schedule(i, alpha)\n",
    "\n",
    "        state = gw.get_init_state()\n",
    "        state_index = gw.get_state_index(state)\n",
    "        action_index = policy(Q, state_index, eps)\n",
    "        while not gw.is_terminal(state):\n",
    "            \n",
    "            next_state, reward = gw.take_action(state, gw.which_action(action_index))\n",
    "            next_state_index = gw.get_state_index(next_state)\n",
    "            \n",
    "            next_action_index = policy(Q, next_state_index, eps)\n",
    "            \n",
    "            q = Q[state_index, action_index]\n",
    "            qn = Q[next_state_index, next_action_index]\n",
    "            Q[state_index, action_index] = q + alpha*(reward + gamma*qn - q)\n",
    "            \n",
    "            state = next_state\n",
    "            state_index = next_state_index\n",
    "            action_index = next_action_index\n",
    "\n",
    "    return Q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_action_value(Q, gw: GridWorld=GW4p1):\n",
    "    print('Action-value table:')\n",
    "    print('State ' + ('  {:>4}  '*4).format(*gw._action.ACTION_LABELS))\n",
    "    for i in range(gw.get_number_of_states()):\n",
    "        print('{}  {:6.2f}  {:6.2f}  {:6.2f}  {:6.2f}'.format(gw.which_state(i), *Q[i]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_resulting_greedy_policy(Q, gw: GridWorld=GW4p1):\n",
    "    print('Resulting greedy policy:')\n",
    "    nl = gw._cols\n",
    "    for state_index in range(gw.get_number_of_states()):\n",
    "        action_label = '×'\n",
    "\n",
    "        if not gw.is_terminal(gw.which_state(state_index)):\n",
    "            action_index = np.argmax(Q[state_index])\n",
    "            action_label = gw.action_label(action_index)\n",
    "\n",
    "        print(action_label, end=' ')\n",
    "        if (state_index + 1) % nl == 0:\n",
    "            print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eps_greedy_policy(q, state_index, eps):\n",
    "    \"\"\"\n",
    "    eps=0 for greedy action,\n",
    "    eps=1 for random action\n",
    "    \n",
    "    returns action index\"\"\"\n",
    "    if np.random.random() < eps:\n",
    "        return np.random.randint(q.shape[1])\n",
    "    else:\n",
    "        return np.argmax(q[state_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eps_exp_decay(iteration, prev_eps):\n",
    "    prev_eps = prev_eps or 1\n",
    "    return 0.99*prev_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action-value table:\n",
      "State      ↑       ↓       ←       →  \n",
      "(0, 0)    0.00    0.00    0.00    0.00\n",
      "(0, 1)   -1.35   -1.39   -1.00   -1.76\n",
      "(0, 2)   -2.21   -2.14   -2.00   -2.19\n",
      "(0, 3)   -3.05   -2.98   -2.98   -3.14\n",
      "(1, 0)   -1.00   -2.10   -1.52   -1.51\n",
      "(1, 1)   -2.00   -2.08   -2.00   -2.04\n",
      "(1, 2)   -2.82   -2.82   -2.84   -2.83\n",
      "(1, 3)   -2.09   -2.00   -2.05   -2.17\n",
      "(2, 0)   -2.00   -2.17   -2.07   -2.24\n",
      "(2, 1)   -2.82   -2.83   -2.83   -2.83\n",
      "(2, 2)   -2.08   -2.00   -2.21   -2.00\n",
      "(2, 3)   -1.48   -1.00   -1.63   -1.48\n",
      "(3, 0)   -2.97   -3.12   -3.11   -2.97\n",
      "(3, 1)   -2.15   -2.18   -2.12   -2.00\n",
      "(3, 2)   -1.79   -1.29   -1.55   -1.00\n",
      "(3, 3)    0.00    0.00    0.00    0.00\n",
      "\n",
      "Resulting greedy policy:\n",
      "× ← ← ↓ \n",
      "↑ ↑ ↓ ↓ \n",
      "↑ ↑ ↓ ↓ \n",
      "→ → → × \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# World from example 4.1\n",
    "q = Sarsa(\n",
    "    gw=GW4p1,\n",
    "    maxiters=1000,\n",
    "    policy=eps_greedy_policy,\n",
    "    eps_schedule=eps_exp_decay,\n",
    "    alpha_schedule=constant_alpha_schedule_factory(0.1),\n",
    "    gamma=1,\n",
    ")\n",
    "print_action_value(q)\n",
    "print_resulting_greedy_policy(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# World from example 6.5\n",
    "class WindyGridWorld(GridWorld):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        rows,\n",
    "        columns,\n",
    "        terminal_states: 'Iterable[(row, col)]',\n",
    "        horizontal_wind=None,\n",
    "        vertical_wind=None,\n",
    "    ):\n",
    "        super().__init__(rows, columns, terminal_states)\n",
    "        self._h_wind = horizontal_wind\n",
    "        self._v_wind = vertical_wind\n",
    "        \n",
    "    def take_action(self, state, action):\n",
    "        r, c = state\n",
    "        if self._v_wind:\n",
    "            r -= self._v_wind[c]\n",
    "        if self._h_wind:\n",
    "            c -= self._h_wind[r]\n",
    "        return super().take_action((r, c), action)\n",
    "        \n",
    "GW6p5 = WindyGridWorld(7, 10, ((3, 7),), vertical_wind=(0, 0, 0, 1, 1, 1, 2, 2, 1, 0))\n",
    "\n",
    "GW6p5.get_init_state = lambda: (3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action-value table:\n",
      "State      ↑       ↓       ←       →  \n",
      "(0, 0)  -21.59  -20.56  -21.41  -21.43\n",
      "(0, 1)  -21.55  -21.14  -21.62  -18.60\n",
      "(0, 2)  -20.38  -17.08  -20.40  -20.20\n",
      "(0, 3)  -18.53  -17.78  -18.48  -15.75\n",
      "(0, 4)  -15.94  -16.22  -16.85  -14.54\n",
      "(0, 5)  -13.56  -14.68  -15.05  -11.08\n",
      "(0, 6)  -14.37  -15.00  -15.16   -9.81\n",
      "(0, 7)  -12.36  -13.74  -13.60   -8.69\n",
      "(0, 8)  -12.11  -12.22  -13.79   -7.57\n",
      "(0, 9)   -8.93   -6.40  -11.25  -10.85\n",
      "(1, 0)  -22.29  -21.57  -20.35  -19.63\n",
      "(1, 1)  -19.95  -19.24  -19.84  -17.95\n",
      "(1, 2)  -18.35  -18.31  -19.50  -16.58\n",
      "(1, 3)  -16.61  -16.55  -18.09  -14.79\n",
      "(1, 4)  -15.30  -15.78  -15.80  -14.43\n",
      "(1, 5)  -15.47  -14.32  -14.93  -11.11\n",
      "(1, 6)  -16.24  -14.55  -17.32  -11.86\n",
      "(1, 7)  -13.18  -12.57  -14.29  -10.98\n",
      "(1, 8)  -10.34  -12.70  -12.29  -12.10\n",
      "(1, 9)  -10.95   -5.19  -12.75   -7.02\n",
      "(2, 0)  -20.78  -20.89  -20.09  -18.25\n",
      "(2, 1)  -19.43  -19.43  -20.57  -18.29\n",
      "(2, 2)  -17.57  -18.03  -19.77  -17.63\n",
      "(2, 3)  -16.59  -17.24  -16.87  -15.87\n",
      "(2, 4)  -14.56  -16.54  -16.25  -12.40\n",
      "(2, 5)  -18.04  -17.26  -17.77  -13.64\n",
      "(2, 6)  -13.43  -16.53  -12.62  -10.88\n",
      "(2, 7)  -12.94  -12.87  -11.89  -12.60\n",
      "(2, 8)  -10.62  -11.54  -11.16  -10.84\n",
      "(2, 9)   -9.32   -5.81  -10.44  -10.79\n",
      "(3, 0)  -20.78  -21.01  -20.70  -17.42\n",
      "(3, 1)  -18.97  -19.30  -21.23  -15.83\n",
      "(3, 2)  -17.84  -18.32  -19.96  -15.41\n",
      "(3, 3)  -16.55  -16.62  -17.73  -14.34\n",
      "(3, 4)  -18.08  -18.78  -18.26  -16.20\n",
      "(3, 5)  -16.16  -15.43  -15.73  -11.83\n",
      "(3, 6)  -14.54  -12.83  -15.07  -14.39\n",
      "(3, 7)    0.00    0.00    0.00    0.00\n",
      "(3, 8)  -11.92  -10.34  -12.33   -8.73\n",
      "(3, 9)   -8.30   -3.01   -9.98   -7.95\n",
      "(4, 0)  -21.19  -21.05  -21.57  -20.18\n",
      "(4, 1)  -19.20  -21.75  -21.83  -20.18\n",
      "(4, 2)  -20.92  -17.35  -22.02  -19.50\n",
      "(4, 3)  -16.37  -19.15  -19.37  -18.41\n",
      "(4, 4)  -15.40  -16.94  -16.46  -12.70\n",
      "(4, 5)  -17.38  -16.35  -17.45  -14.08\n",
      "(4, 6)    0.00    0.00    0.00    0.00\n",
      "(4, 7)  -11.97   -1.00  -12.55   -9.16\n",
      "(4, 8)  -11.16   -2.00   -1.00   -5.56\n",
      "(4, 9)   -6.83   -8.88   -2.00   -4.25\n",
      "(5, 0)  -21.53  -21.26  -20.24  -17.67\n",
      "(5, 1)  -20.31  -20.49  -21.07  -16.37\n",
      "(5, 2)  -20.68  -18.87  -19.45  -15.79\n",
      "(5, 3)  -16.59  -17.25  -19.41  -15.67\n",
      "(5, 4)  -17.67  -17.59  -18.57  -14.97\n",
      "(5, 5)    0.00    0.00    0.00    0.00\n",
      "(5, 6)    0.00    0.00    0.00    0.00\n",
      "(5, 7)  -11.74   -2.34  -14.21  -11.54\n",
      "(5, 8)   -9.33   -7.43   -7.71   -3.29\n",
      "(5, 9)   -8.41   -8.09   -5.22   -7.88\n",
      "(6, 0)  -21.08  -20.66  -20.87  -20.22\n",
      "(6, 1)  -19.64  -20.29  -20.68  -18.93\n",
      "(6, 2)  -19.33  -19.06  -19.71  -17.74\n",
      "(6, 3)  -17.90  -18.34  -18.44  -16.51\n",
      "(6, 4)    0.00    0.00    0.00    0.00\n",
      "(6, 5)    0.00    0.00    0.00    0.00\n",
      "(6, 6)    0.00    0.00    0.00    0.00\n",
      "(6, 7)    0.00    0.00    0.00    0.00\n",
      "(6, 8)   -2.00   -7.65   -5.49   -7.92\n",
      "(6, 9)   -7.59   -7.68   -3.73   -6.62\n",
      "\n",
      "Resulting greedy policy:\n",
      "↓ → ↓ → → → → → → ↓ \n",
      "→ → → → → → → → ↑ ↓ \n",
      "→ → ↑ → → → → ← ↑ ↓ \n",
      "→ → → → → → ↓ × → ↓ \n",
      "→ ↑ ↓ ↑ → → ↑ ↓ ← ← \n",
      "→ → → → → ↑ ↑ ↓ → ← \n",
      "→ → → → ↑ ↑ ↑ ↑ ↑ ← \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# World from example 4.1\n",
    "q = Sarsa(\n",
    "    gw=GW6p5,\n",
    "    maxiters=20000,\n",
    "    policy=eps_greedy_policy,\n",
    "    eps_schedule=lambda a,b: 0.1,\n",
    "    alpha_schedule=constant_alpha_schedule_factory(0.5),\n",
    "    gamma=1,\n",
    ")\n",
    "print_action_value(q, GW6p5)\n",
    "print_resulting_greedy_policy(q, GW6p5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3*: Eligibility trace\n",
    "\n",
    "Do a random walk in example 4.1 gridworld, and create an eligibility trace from the walk.\n",
    "\n",
    "*) - not mandatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ET(gw: GridWorld, decay):\n",
    "    E = np.zeros((gw._rows, gw._cols))\n",
    "\n",
    "    path = []\n",
    "    state = gw.get_init_state()\n",
    "    while not gw.is_terminal(state):\n",
    "        path.append(state)\n",
    "        E *= decay\n",
    "        E[state] += 1\n",
    "        action = random.choice(gw.get_actions(state))\n",
    "        state, reward = gw.take_action(state, action)\n",
    "        \n",
    "    path.append(state) # make it print nicely\n",
    "\n",
    "    with np.printoptions(formatter={'float':'{:6.2f}'.format}):\n",
    "        print(\n",
    "            f'Path length: {len(path)}\\n'\n",
    "            f'Eligibility trace:\\n{E}'\n",
    "         )\n",
    "        \n",
    "    sns.heatmap(E)\n",
    "    p = np.asarray(path).T + 0.5\n",
    "    p = (np.random.random(p.shape) - 0.5)/3 + p\n",
    "    plt.plot(p[1], p[0], 'wo--')\n",
    "    plt.plot(p[1, 0], p[0, 0], 'c*', markersize=15)\n",
    "    plt.plot(p[1, -1], p[0, -1], 'mX', markersize=20)\n",
    "    plt.gcf().set_size_inches(9, 7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path length: 7\n",
      "Eligibility trace:\n",
      "[[  0.00   1.90   0.00   0.00]\n",
      " [  0.00   0.81   0.73   0.00]\n",
      " [  0.00   0.00   0.66   0.00]\n",
      " [  0.00   0.00   0.59   0.00]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAGfCAYAAACp5SATAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xt8XHWd//H3ZyaTa9MCbaHQFopYhHIpQsBFkIugFnVFRBF0RXeB7Pr7gfrbVZcFRcHFZQsqy2/x0nVZ1stPQFGBXQRXBREp2FLaQlsuLbT0Bm3a0jTJZG7n+/tjJmmaZi5t58w5c+b15HEej2TmZPJJE/LO93O+3+8x55wAAEB9iwVdAAAA2HcEOgAAEUCgAwAQAQQ6AAARQKADABABBDoAABFAoAMAEAEEOgAAEUCgAwAQAU2+f4LmqWxFFyLJDX8IugSM0nbIO4IuAQi1bHq9+f05Mj0vVy2rEpPe5Hu9Y2GEDgBABPg+QgcAIPS8XNAV7DNG6AAARAAjdAAAnBd0BfuMQAcAwKv/QKflDgBABDBCBwA0PEfLHQCACKDlDgAAwoAROgAAtNwBAIgANpYBAABhwAgdAABa7gAARACz3AEAQBgwQgcANDw2lgEAIApouQMAgDBghA4AAC13AAAigI1lAABAGDBCBwCAljsAABHALHcAABAGjNABAKDlDgBABNByBwAAYcAIHQDQ8Jyr/3XoBDoAABG4hk7LHQCACGCEDgAAk+Iw2mxvln6UuVWzvVlVOQ8AUAPOq94REAK9imZ7s3Rj7vOaosm6Mfd5zfaOrvA8Qh0AAuXlqncEhECvkqGQblWLJKlVLbox94XdQn3s8wh1AMC+IdCrYHRIDxkd6qXPI9QBIDC03FEspIcMhfpFufdXcB6hDgCB8LzqHQEh0PfRF3LdRUN6SKtadKn3oYrO+0Kuu5rlAQAaBIG+j26Oz9OgUmXPKxfmkjSolG6Of68aZQEA9gQtdyyJLde18VsqCvVSBpXStfGbtSS2okqVAQAqRssd0r6HOmEOANhXBHqV7G2oE+YAEAKM0DHSkthy/SD284pDPRPL6KfjHiTMASBgzuWqdgSFQK+i2d6simazD0l4CX3Su1BL/uM3+vjHL5QkxeNxjRvX4WeZAIAI4uYsVVJuPXox3oCnTX/1mtpPyn/cSScer8f/cL+ef2GlFi5cooULF2vhwiVavGSZ0um0H6UDACJwcxYCvQr2NsyHWNp0/vxz9af4M3p902bd8LVvqKvrBL37XWfq0k98RJJ07rs+okd//4SOP36Wuk6aracXLdWyZS8om81W80sBgMYUgfuhlw10MztK0vmSphYeWi/pfuccF36172E+ZGhHuWtfuVn/eOOtw49Pm3aITjrpeC1YuFiS9Ofvf7eu/+oXJEnJZFKLFy/TwqeX6Etfvkn9/QP7VAMAoH6Zc674k2Z/L+kSSXdJWld4eJqkiyXd5Zy7qdwnaGqeWvwTRMCPMrdqiiaXPW9QqYpC/zVt1l8kPlfynCOOmKGurtnqOnG2urpm64gjZuiww7vknNPcm76sE088XgufXqwFC5fo6aeXaPXqtcMfm9zwh/JfFGqq7ZB3BF0CEGrZ9Hrz+3MkfzuvalnVdk637/WOpdwI/TJJxzjnMiMfNLNvSlomacxAN7NuSd2SZPEJisWiO8nr5vi8siP0QaX0g9i9utS7sOx5N8fnlf2cq1at1qpVq3X33fft9tzrmzaro6NNV115mVpa8p9rwcLFOvXt75MkWVOLXC4rBTgTEwBCJwIt93Ij9Oclvcc5t2bU44dJ+rVz7i3lPkHUR+hS6bb7yHXm5c+7RUtiy6tSUyKR0HHHHqWurhMkSfP+7YeSpExyjSzeJJfLymVT+SOTlMvu20532HuM0IHSajJC/813qzdCP/dvAhmhlwv0OZL+VdJLkob6todKerOkK51zD5X7BI0Q6NLYoT7WpjHFz6temJcyuOlPsqaWEUezcsnt8vq3SJLi4ybL5dJymZRcLiWV+PlAdRDoQGk1CfRff7t6gf7u/xW+lrtz7iEzO1LSKdp1UtwCF+Tq+RBaEluua3XLcFgX2wFu7PNqE+aShkflwywmqfCzF2uSJVoVa+3Mn+uclMsoN7BVLj004c4kEfIAIiYCLfeys9ydc56kJ2tQS90bCusv5Lp1c/x7RXeA2/W8eTUL8zGN/CH2sspuWytZbOcIPtEyvD7TEm2Kj58i5dLyMqmdfxzkWB8PAEEr2XKvhkZpudeLfZrlHk8o1jJuZ9jH4pKkzLZ1Ui4ta2qR4olCyGfKvBiG0HIHSqtJy/1Xt1Wv5X7eZ8LXcgd2kcvIG9i28/1YUz7ECyN0axmneNsESZLzvOERvDewdcyXs+YOxTsOkGJNkpdVrn+rXLrf9y8DAHbDTnFoaF5WLr1zpzqvf4u8wd5dJt3FWjqGAz3WMVE2NIKXKdY2XmaF2wnEE4p3TlZuhwh1ANgLBDqqK5eRy2XkUn27P+c8WSwua9tPZrt3pMxiinccoCyBDqDWGmFSHFAt3sC2Qsve1DRxxpihrlgTrXgAtVfDlruZ3SHp/ZI2OeeOLXLOWZJulZSQ1OOcO7Pc63L7VATASV7xm8rEOw+UxRMyM1mhFW/N0d1tEEDDuVPSnGJPmtl+kr4t6QPOuWMkfaSSFyXQEYhc/1a5US0u5zzJud1G7kOteADwjfOqd5T7VM49Jmns2cJ5H5P0c+fcq4XzN1XyJRDoCIRL9yu3Y3P+ertzcrmMcjs2S2O14aV8+x0A/OJ5VTvMrNvMFo44uvewmiMl7W9mj5rZ02Z2aSUfxG9JBMal+3efAOdlpXhi95NLtOgBIEycc/Mklb/TVnFNkk6SdI6kNknzzexJ59yL5T4ICI1c/9b8NXPb2TxyzlOuv1R3CgD2Ubhmua+TtMU51y+p38wekzRbUslAp+WOUNnZis8WWvHZ/PvMcgfgpyq23KvgPkmnm1mTmbVLepuksfcSH4EROkLHpfuV87Jq2m+qsn2b5TLJoEsCgKoxs59IOkvSJDNbJ+kryi9Pk3Puu865FWb2kKSlkjxJ33fOPVfudQl0hNLwPQaKTZIDgGqq4Tp059wlFZxzs6Sb9+R1CXSE1NB9Egh0ADXg843KaoFr6AgnRugAsEcYoSOcnCcv3S95uaArAdAIuNsa4BPnKdf7etBVAGgUEQh0Wu4AAEQAI3SEVtP+h8ob7JWXfCPoUgBEXbg2ltkrBDrCKxaTjCYSgBqg5Q74yDlmuQNAhRihI7zGuJUqAPgiAuvQCXSEmBNNJAA1EYGWO4GO0PJS/dw2FQAqRKAjtLwBbpkKoEYYoQMAEAERWLbGBUqEVrzzIMUnHBJ0GQBQFxihI9SY5Q6gFpzHLHfAR6xDB1AjEbiGTssd4eVYtgYAlWKEjtByzqPlDqA2IjApjkBHaLnMoLwI7N4EoA5wDR3wj0v3y6X7gy4DAOoCgQ4AQAQmxRHoCK1Y6wTFx01UZssrkbhxAoAQI9ABPw2FeExSLshCAERdBAYNrAlCaLmhWafMdAeAshihI7yG/mIm0AH4jZY74KehFhiBDsBnEVi2RssdoeVyGeUGtkmO6+cAUA4jdIRXLiNvYFvQVQBoBOwUB/jMYoVr6fXfDgMQYhFouRPoDeaBY78UdAkVG3/UNJ376Fw9dcW/aP0DTwVdjm++c+DZQZeAET696ZGgSwD2CoGO0Mol05KkeGtzwJUAiDrHLHfAP7lURpIUa0kEXAmAyItAy51Z7git3CAjdACoFCN0hNbOQGeEDsBnzHIH/OOlslp20z3qefL5oEsBEHURaLkT6Agv5/TCrb8MugoAqAsEOkKt7eAD5GWySvX0Bl0KgCiLwCx3JsUh1M5+6Gua9fcXBV0GgKjzXPWOgBDoCLXcYIZJcQBQAVruCLXcYFrxNpatAfAZs9wBf+UG02wsA8B/EZjlTssdoZZLptlYBgAqwAgdobZy3q/kIvCXM4BwYy93wGcbHlwQdAkAGkEEBg603BFqbQcfoM63TA26DAAIPQIdoTbrHy7S23/0xaDLABB1EViHTssdocakOAA1EYFla4zQEWq5wTQbywBABRihI9S8VIYROgD/RWBSHIGOUMsNphVLNMniMblc/bfEAIRTFJbHEugItQ2/Wqj+NZuCLgMAQo9AR6j1rlir3hVrgy4DQNQxQgf81TyxU50zp2rb4lXyBjNBlwMgqiKwUxyz3BFqB515vM785XVqP2Ri0KUAQKgxQkeo5QbTksRMdwD+ouUO+Gso0GMEOgA/RSDQabkj1HKp/HVzNpcBgNIYoSPUckla7gD851z9j9AJdIRa36qNmv+pb+qNpa8EXQqAKItAy51AR6hltvdr40MLgy4DAEKPa+gItVhzkw465wS1T58UdCkAoiwCt08l0BFqTZ1tOu3HX9SUd50YdCkAIsx5rmpHUAh0hBqT4gCgMlxDR6h5Q8vWWli2BsBHTIoD/OVynrxMlhE6AH/V/1butNwRfrnBtGJsLAMAJTFCR+jNv/QWJTduC7oMABEW5GS2aiHQEXo9858PugQAUReBQKfljtA76OzjNfHPjgq6DAAINUboCL1jrrlYyQ1bNP9JRuoAfBKBSXEEOkIvN5hWjGVrAHwUhWvotNwRernBNMvWAESGmd1hZpvM7Lkiz3/czJaa2bNm9oSZza7kdQl0hJ6XyijeRqAD8JFXxaO8OyXNKfH8K5LOdM4dJ+lrkuZV8qK03BF6jNDryxEfPFUnX32Rxh0ySX0berTgpnu06pfzgy4LKKmWLXfn3GNmNqPE80+MePdJSdMqeV0CHaH33D/epVgzP6r14IgPnqp3zL1cifYWSVLntMl6x9zLJYlQR8Mws25J3SMemuecq2iUPYbLJP2qkhP5LYnQ61/9etAlNKx4a7Oc58lLZ9U8oV0HvvXNau5sU/P49vzR2a6X7n1c21dt1EFdM3XGN7rVNGoCY6K9RSdffRGBjnCr4iz3QnjvbYAPM7OzlQ/00ys5f68D3cz+0jn3H3v78UCl9n/rEZpw9HSt/n+PBl1KXbF4TM2d7fKyOWX6koq3Nmv6Wccr0dmmlqFAHt+uNb9epI3zV2j84Qfpnf/6v3cJ63hzkx757He08t4/av8jp+m8H31xl8/hZXPavHiVtq/aKOd5ihfppIw7ZGItvmRgr7mQLVszs+MlfV/Sec65LZV8zL6M0K+XNGagj2w3WHyCYrGOffg0aHSHvO9kvfnyOQ0X6ImOVjWPzwdycvN2SfmWdnPnzjBuGd+ujU8+r1X3zVeio1XnP3C9mse3qbmzXYmOVknSwlt+pmdu/aVaJrTrXd//3C6fI92X1PZXXtfG+SuUG8wo2dOr7a+8pvT2AaV3DCjdO6Atz62RJG1d/qru+8BX84/vSCq9fUDZZGr4tTYtWqW+9T3qnDZ5t6+lb0NFv4+A4IQo0M3sUEk/l/QJ59yLlX5cyUA3s6XFnpJ0ULGPG9luaGqeWv+L+xAoL5Wpu0lxseYmJca3KzG+Xc5J/a+8Jkma9sFT1Tpl/+HnEuPb9dqL67X0u/8tSfrQwzeqY+pENXe2KxbPL0J58Z7H9Pu/zXfvzrjlCjUV/i1y6azSvf1KbtkhScomU9r20npldgwoNSKQX396pSQp2dOre999jTI7ksOh7HI7f4v1b9yqhz95S9GvKdM/qE2LVpb8uhfcdI/OuPlyNbW17Py4gZQW3HTPHv37AVFmZj+RdJakSWa2TtJXJCUkyTn3XUnXSZoo6dtmJklZ51xXudctN0I/SNJ7JI2+M4ZJemL304HqmnbB23XEZfnVHXMW3qbnbrxL637h84+emRKdbWoqjIItEdcbS16RlO8WdM6cqsSEdiU684Gc6unVkmvulCSddtfVmvS2o3ZZZtczf4Ueu+BrkqSj/vZDGn/kVDnPU2ZHUpneAQ0U7vkuSRueWK5YU1zp3gGlevOh/MaL64efv/fcf1Cmf1DpHQPKDe78OCk/S/e3f31b0S/L5TxtXf7qPv/zlDJ0nTw/y32i+jZsYZY76kItW+7OuUvKPH+5pMv39HXLBfp/SRrnnFs8+gkze3RPPxmwJ6Zd8Had+I0r1FSYMd0+bZJO/MYVklQy1ONtzcOj36bOdiU627Tp989Kkqace4IO6Dpyl0C2mOmJv7hZktT1fz+t6ReeJovt3KIhuWGLfnXiVZKkGZecpSnnvlXZgZQyvQPK9A6o94V1w+e+/shSbV+2Zvi5TO+AkiPazX/40NeUS2WU7RuUXL55taVp5+d68vofl/w36a2DCYKrfjlfax5eJOeccoPpoMsBKhOilvveKhnozrnLSjz3seqXA+x0zDUfHQ7zIU3tLXrr3L/SgWccmw/kCflQ/sOFNyrbl9QxX7pYb7nyA7u91i+mf0Iuk9NB7zxBh196jjLbB5TZMaBs74BS2/qGz3vtN4vV/+qm4ecz2weU3rZj+Pmnum+Tl87KZXNj1rzyew+W/JpSPb178k9Qtz7x7He07I6H9aev3x10KUDDYNkaQqt96tgzo5vGtenAM47bGcibtyuWiEvKj5Azb/TvMkLObB8Yvla89LofDrfHx7LuvtKt4dxAquTzyMsmU7tcRwfCLmyz3PcGgY7QGli/RR3Td58xPbCuRw+f/NkxP6bnj8vV88flRV+z2Mga1ZUdzKiJ7XpRR6IQ6OzljtBa9vW7lR01Is4OpLSMNm7o5ZIpxVsZoQO1xAgdoTU08e2Yaz6q9qkTNbB+i5Z9/W7/Z7ljn2WTaUboqCtRGKET6Ai1db94ggCvQ8t/8Btl+gaDLgOonLOgK9hnBDqAqnv+x48EXQLQcAh0AFXXPL5dTW3NGnj9jaBLASoShZY7k+IAVN3p//SXet891wZdBlAx51nVjqAQ6ACqjklxQO3RcgdQddnBFIGOuhKFljuBDqDqsgPsFIf64iIwy52WO4CqyybT+du8Wv3/kgTqBSN0AFW39tGlSr3RJ4uZXM4FXQ5QFi13ABjD5mdWafMzq4IuA6hYkLPTq4WWO4CqS4xr0/5vmaZYM2MGoFYIdABVN/3s4/Xh396k8YceGHQpQEWcq94RFP58BlB12WRakli6hrpByx0AxrAz0Fm6BtQKI3QAVZdN5u9jzwgd9SIKI3QCHUDVZQcZoaO+BHntu1pouQOour71Pfr9381Tz3Orgy4FaBiM0AFUXXr7gF68+7GgywAqRssdAMZgMdOk2W/SwGvb1L9xa9DlAGWxlzsAjCGWaNIHH7heb/7QaUGXAjQMRugAqi6Xysh5HrPcUTfYyx0Aihi+4xpQBzxa7gAwtmySe6IDtcQIHYAvssm0mtoJdNSHKEyKI9AB+OKP196pZE9v0GUAFWHZGgAUsfZ3S4IuAWgoBDoAX0w8dobizU3atGhl0KUAZUVh61cCHYAvTr76IrVMaNd9f/7VoEsByopCy51Z7gB8kU2mFGfZGlAzjNAB+CKbTLNsDXUjCuvQCXQAvsgmU2wsg7oRhWVrtNwB+CI/QifQgVphhA7AFyt++FutefjpoMsAKsIsdwAoYvuqjdq+amPQZQAVicI1dFruAHzRediBetMH/kyxZsYNQC0Q6AB8Me0dx+qcb1+plgkdQZcClOWcVe0ICn86A/BFNpmWJCbGoS5E4Ro6I3QAvsgOpiSJtehAjTBCbzAXbf190CVglK8ffHbQJfhi/1R+hD7Q0axt8YCLAcqIwqQ4Ah2ALzKFlnuCETrqQBQ2liHQAfji9edW6wcfuE5bWboG1ASBDsAX6b6kXlvyctBlABWJQsudSXEAfJFob9FxHz1TBxxxcNClAGW5Kh5BIdAB+KJ5XJvOm3uFDv2zo4MuBSjLc1a1IygEOgBfZJIsWwNqiWvoAHwxvLFMayLgSoDymOUOAEV42ZxymSzL1lAXvKALqAJa7gB8kxlIKdHK1q9ALTBCB+CbH13wVSW39QVdBlCWEy13ACiKTWVQLzxuzgIAxR19/qmaOacr6DKAhsAIHYBvTvrUezTY26+XHloYdClASR4tdwAoLptKMykOdSEK19BpuQPwTSaZVqKdZWtALTBCB+CbTDLFTnGoC1FYh06gA/BNNknLHfUhCi13Ah2Ab353w49ksfr/RQnUAwIdgG8Gt/cHXQJQkSi03JkUB8A30992lE7//IeDLgMoy6viERQCHYBvDjlppt5+1QcVb+GOa4DfaLkD8M3QLVQTrc3KpTIBVwMUx6Q4ACghk0xJUn7pGtfTEWJe/ec5LXcA/skOFkbobSxdA/zGCB2AbzKFlnsTa9ERcuzlDgAlrPrdM/rWUZcpUxipA2EVgbun0nIH4B8vk8tfR3dR+HUJVI+ZzTGzF8xspZldPcbzh5rZI2b2jJktNbP3lntNAh2Ab8YduJ/O/vLHNfnoQ4MuBSipluvQzSwu6XZJ50maJekSM5s16rQvSbrHOfdWSRdL+na51yXQAfimeXy7Tr78PE084uCgSwFK8syqdlTgFEkrnXMvO+fSku6SdP6oc5yk8YW3J0jaUO5FuYYOwDfZkcvWAAyZKmntiPfXSXrbqHO+KunXZnaVpA5J55Z7UUboAHyTHcxvJsOyNYSdq+JhZt1mtnDE0b0XJV0i6U7n3DRJ75X0QzMrmdmM0AH4ZmhjmQQjdIRcNfdgd87NkzSvxCnrJU0f8f60wmMjXSZpTuH15ptZq6RJkjYVe1FG6AB8M7SxTLyZsQMwwgJJM83scDNrVn7S2/2jznlV0jmSZGZHS2qVtLnUi/J/GQDfOM9p7oxPsGwNoVfLrV+dc1kzu1LSw5Liku5wzi0zsxskLXTO3S/p7yT9m5n9H+U7+Z9yrvT/SAQ6AH8R5qgDtd4pzjn3oKQHRz123Yi3l0s6bU9ek5Y7AF+defVHdfzFZwVdBhB5BDoAX818T5cOe/sxQZcBlFTNWe5BoeUOwFeZZEpNLFtDyHH7VAAoI5NMsw4dqAFG6AB8lU2m2CkOoVfNdehBIdAB+Cq5rU/tcZqBCLcorMUg0AH46oGrbg+6BKAhEOgAgIbHpDgAKOOYC9+h933rb4IuAyiplvdD9wuBDsBXk2YeoiPfe0rQZQCRVzbQzewoMzvHzMaNenyOf2UBiIpMMq1Ea7NkEehpIrIiP0I3s89Iuk/SVZKeM7PzRzz9dT8LAxANQ3dcS7SyFh3h5ax6R1DKTYq7QtJJzrk+M5sh6WdmNsM59y9S8Z3sCzdz75Yki09QLNZRpXIB1Juhe6I3tTUPvw2g+soFesw51ydJzrnVZnaW8qF+mEoE+sibuzc1T43C8j4Aeym5rU9vrN2keFM86FKAohphY5nXzewE59xiSSqM1N8v6Q5Jx/leHYC69/wDT+r5B54MugygpEYI9EslZUc+4JzLSrrUzL7nW1UAIuPo80/VGV+8SOMPmaTeDT16bO49WnHf/KDLAiKnZKA759aVeO6P1S8HQJQcff6pOm/uFWoqTIibMG2y5tx0uSQR6giVKFwbZh06AN+c8cWLhsN8SKK9RWd88aKAKgLG5ln1jqAQ6AB8M/6QSUUen1jjSoDoI9AB+KZ3Q0+Rx7fUuBKgtMhvLAMA++KxufcMbywzJDOQ0mNz7wmoImBsBDoAlLDivvl64rZfKpfJynlO29dt1kNXf58JcYAPuH0qAF89efv9evL2+4MuAygpCrPcCXQAQMPjfugAUMaBxxymj//iKzro2BlBlwIUxTV0ACijpbNdU0+cqZbOtqBLASKNljsAXw3dBt1F4SIlIisKP54EOgB/xfKNQOdF4fYXiCovApFOyx2Ar4bnGtX/70sg1BihA/BVakdS659+Uam+ZNClAEVFoX9EoAPw1WtLX9aPP3RD0GUAJUWhgUTLHQCACCDQAfhqatdM/eWv/0kHzjo06FKAoqKwDp2WOwBfNXe0afJbpu92X3QgTNgpDgDKGVqH7kXhKiUQXozQAfjKhtahs7MMQiwK69AJdAC+Yh066kEUfjxpuQPw1cDWHXrl90uV2jEQdClApDFCB+CrjYtX6aeXzg26DKAkNpYBACAConANnZY7AF8ddvqx+us/3qpJR04LuhQg0hihA/BVor1FE6ZNUiwRD7oUoKj6H58T6AB8ZtwQHXUgCtfQabkD8Bd5DtQEI3QAvmKEjnoQhUlxBDoAX+14bateePBPrENHqNV/nBPoAHy28ZlVuu/TtwVdBhB5BDoAoOExKQ4Aypj5ni5dteS7OuBNBwddClCUq+J/QSHQAfgq3tyktv3GSbEI3HAaCDFa7gB8xSx31IMotNwJdAD+GhqYk+cIsSgsW6PlDsBXQyN0xwgd8BUjdAC+euPVTXr2nseU7ksGXQpQVBT+3CTQAfhqw6KV2rBoZdBlACXRcgcAAKFAoAPw1awLTtPfrbxTE6ZPDroUoCivikdQaLkD8FUsHlM8wa8ahFuQG8JUCyN0AP5iljtQE/zZDARsu0VhS4viBi0f5DvkRf5rRf2Kwk8mgQ7AX4zQUQdouQNAGZtWrtf8Ox9Wqm8w6FKASGOEDsBXaxe9pLWLXgq6DKAkWu4AUEYsHlOsKa5sKhN0KUBRXgQuCdFyB+Crky46S9e/8J/qPHC/oEsBIo0ROgB/cRt01IH6H58T6AB8tvN+6MHWAZTCXu4AUM7QsrUI/MIEwowROgBfDXXcWYeOMIvCH5wEOgBfbVi2Wo/efp8yA6mgSwGKYtkaAJSx9pmVWvsM90MH/MY1dAC+ampJqH3/zp2T44AQ8uSqdlTCzOaY2QtmttLMri5x3oVm5sysq9xrEugAfHXyJe/Utc98T63j24MuBSjKVfG/cswsLul2SedJmiXpEjObNcZ5nZI+K+mpSr4GAh2AvxiZA6OdImmlc+5l51xa0l2Szh/jvK9J+mdJFd0IgUAH4KvhZej1P4kYEeZV8ajAVElrR7y/rvDYMDM7UdJ059x/V/o1MCkOgL+GR+gkOsKrmssqzaxbUveIh+Y55+btwcfHJH1T0qf25PMS6AB8ZeJ+6GgshfAuFeDrJU0f8f60wmNDOiUdK+nRwmTSKZLuN7MPOOcWFntRAh2Ar9YsfEEPz72Lu60h1Gq89esCSTPN7HDlg/xiSR8betJpmGPWAAAIYklEQVQ5t13SpKH3zexRSZ8vFeYSgQ7AZ+uWrNK6JauCLgMoqZYbyzjnsmZ2paSHJcUl3eGcW2ZmN0ha6Jy7f29el0AH4KvW8e1qG9+hN9b30HZHaNV661fn3IOSHhz12HVFzj2rktdkljsAX518yTv1+cf/RU2tzUGXAkQaI3QA/mLdGupAFG6fSqAD8NXOPK//X5iIrij8fNJyB+AvdooDaoIROgBfsQ4d9YDbpwJAGSv/sFSpvqS8bC7oUoCiaj3L3Q8EOgBfrX/2Fa1/9pWgywAij0AH4KuOSeM1btIEvf782vInAwGJwix3JsUB8NUpHztHn3non2UxJschvJxzVTuCQqADqI36HwABoUbLHYCvjGVrqANRaLkT6AD8ZSxbQ/hFYZY7LXcAvmKADtQGI3QAvlr+8EJtXbs56DKAkrwIdJAIdAC+2rh8jTYuXxN0GUBJ9R/ntNwB+Gy/qZM0/cSZQZcBRB6BDsBXJ3/sHF1x95eDLgMoyZOr2hEUWu4AfGXGrdARflFYtsYIHYD/SHTAd4zQAfiLdWuoA1HYJ4FAB+Ars2hs2oFoi0LLnUAH4Ktnfv64Xl20MugygMjjGjoAX61ev1lfOXayBjpagi4FKMpV8b+gEOgAfPXy+V16+bhpeva0I4MuBSiK26cCQAlO0vyzj5bM9Kf3HBeBq5RAeJUNdDM7xcxOLrw9y8z+1sze639pAOrd2iOnqC+en+U+2NGitUdOCbgiYGxR2FimZKCb2Vck3SbpO2b2T5L+VVKHpKvN7Noa1Aegjr3wybM0GMsHerY1oRc+eWbAFQFji0LLvdws9w9LOkFSi6TXJE1zzvWa2S2SnpJ041gfZGbdkrolyeITFIt1VK9iAKH008+8Wy+dOGOXx5rNhn/BOUlLpu2nBXd273LOzEWr9ZHbfl2jKoHoKtdyzzrncs65AUmrnHO9kuScS0ryin2Qc26ec67LOddFmAON4ayfLdD4nh1qSmeHH0uPGq2MfL8pndWEnh0662cLalYjUEzkW+6S0mbWXnj7pKEHzWyCSgQ6gMYzecM2dV/zU818Zo0SqUzJcxODGc1ctFpXXPNTTd6wrUYVAsU1wrK1MwqjcznnRgZ4QtInfasKQF1qTmd1wXd+q3N+Ml8tRbZ8bTHTOXfN1wXf/Z2aR4zmAeybktfQnXOpIo/3SOrxpSIAdW/Kmi2KpbNSIr7bc7F0VlPWbAmgKqA4LwJ7ubMOHUDVbTx8sjJevqlnktpjMQ2N1zOep40zJgVWGzCWRmi5A8AeW3vkFGVbEmpKZzW+Z4fOu/VX6ixMmMu2JFiPDviAm7MAqLr1Rxwoy3mauWi13nfHY2pOZ3X4c+v135edqee7DteGIw4KukRgF1FouRPoAKpu0oY3dPp9izT78ReHHxuaMLfk9CP1/MlvCrA6YHdBtsqrhUAHUHUf/dZDRZ+b/fiLuwQ9gOog0AEADY+WOwAAERCFljuz3AEAiABG6ACAhkfLHQCACKDlDgAAQoEROgCg4e16/7H6RKADABpekPcxrxZa7gAARAAjdABAw3PMcgcAoP7RcgcAAKHACB0A0PBouQMAEAFR2CmOljsAABHACB0A0PCisPUrgQ4AaHhcQwcAIAJYtgYAAEKBEToAoOHRcgcAIAJYtgYAAEKBEToAoOHRcgcAIAKY5Q4AAEKBEToAoOHRcgcAIAKY5Q4AAEKBEToAoOFxcxYAACKAljsAAAgFRugAgIbHLHcAACIgCtfQabkDABABBDoAoOE556p2VMLM5pjZC2a20syuHuP5FjO7u/D8U2Y2o9xrEugAgIZXy0A3s7ik2yWdJ2mWpEvMbNao0y6TtM0592ZJ35L0z+Vel0AHAKC2TpG00jn3snMuLekuSeePOud8Sf9ZePtnks4xMyv1ogQ6AKDhuSoeFZgqae2I99cVHhvzHOdcVtJ2SRNLvajvs9yz6fUl/6KoF2bW7ZybF3Qd2InvSbhE5ftxY9AFVFFUvie1UM2sMrNuSd0jHppXi+8DI/TKdZc/BTXG9yRc+H6ED9+TADjn5jnnukYco8N8vaTpI96fVnhszHPMrEnSBElbSn1eAh0AgNpaIGmmmR1uZs2SLpZ0/6hz7pf0ycLbH5b0O1dmxh0bywAAUEPOuayZXSnpYUlxSXc455aZ2Q2SFjrn7pf075J+aGYrJW1VPvRLItArx3Wo8OF7Ei58P8KH70lIOecelPTgqMeuG/H2oKSP7MlrWhT2rwUAoNFxDR0AgAgg0CtQbos+1JaZ3WFmm8zsuaBrgWRm083sETNbbmbLzOyzQdfUyMys1cz+ZGZLCt+P64OuCbVBy72MwhZ9L0p6l/KL/xdIusQ5tzzQwhqYmZ0hqU/SD5xzxwZdT6Mzs4MlHeycW2RmnZKelvRB/h8JRmE3sQ7nXJ+ZJSQ9LumzzrknAy4NPmOEXl4lW/Shhpxzjyk/6xMh4Jzb6JxbVHh7h6QV2n3XK9SIy+srvJsoHIzcGgCBXl4lW/QBkFS4I9RbJT0VbCWNzcziZrZY0iZJ/+Oc4/vRAAh0AFVhZuMk3Svpc8653qDraWTOuZxz7gTldyA7xcy4NNUACPTyKtmiD2hohWu190r6sXPu50HXgzzn3BuSHpE0J+ha4D8CvbxKtugDGlZhEta/S1rhnPtm0PU0OjObbGb7Fd5uU35C7/PBVoVaINDLKNy2bmiLvhWS7nHOLQu2qsZmZj+RNF/SW8xsnZldFnRNDe40SZ+Q9E4zW1w43ht0UQ3sYEmPmNlS5Qck/+Oc+6+Aa0INsGwNAIAIYIQOAEAEEOgAAEQAgQ4AQAQQ6AAARACBDgBABBDoAABEAIEOAEAEEOgAAETA/wc35p2/qo3BxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 648x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ET(GW4p1, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4**: TD(lambda)\n",
    "\n",
    "Implement TD(lambda) algorithm and use it for solving example 6.5. Create a table/plot on the effect of lambda in the performance of the algorithm.\n",
    "\n",
    "*) - not mandatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SarsaLambda(\n",
    "    gw: GridWorld,\n",
    "    maxiters: 'number of iterations, no early stopping',\n",
    "    policy: 'Callable(q, state_index, eps) -> action_index',\n",
    "    eps_schedule: 'Callable(iteration, previous_eps?) -> eps',\n",
    "    alpha_schedule: 'Callable(episode_num, previous_alpha?) -> alpha',\n",
    "    gamma: 'constant discount factor',\n",
    "    lambda_,\n",
    "    max_episode_length = 200,\n",
    ") -> 'action-value table - 2D array: state_indices×action_indices':\n",
    "    \n",
    "    sa_dims = (gw.get_number_of_states(), gw.get_number_of_actions())\n",
    "    Q = np.zeros(sa_dims)\n",
    "    eps = None\n",
    "    alpha = None\n",
    "    \n",
    "    for i in range(1, maxiters+1):\n",
    "        E = np.zeros(sa_dims)\n",
    "        \n",
    "        eps = eps_schedule(i, eps)\n",
    "        alpha = alpha_schedule(i, alpha)\n",
    "\n",
    "        state = gw.get_init_state()\n",
    "        state_index = gw.get_state_index(state)\n",
    "        action_index = policy(Q, state_index, eps)\n",
    "        j = 0\n",
    "        while not gw.is_terminal(state)  and j < max_episode_length:\n",
    "            j += 1\n",
    "            \n",
    "            next_state, reward = gw.take_action(state, gw.which_action(action_index))\n",
    "            next_state_index = gw.get_state_index(next_state)\n",
    "            \n",
    "            next_action_index = policy(Q, next_state_index, eps)\n",
    "            \n",
    "            delta = reward + gamma*Q[next_state_index, next_action_index] - Q[state_index, action_index]\n",
    "            \n",
    "            E[state_index, action_index] += 1\n",
    "            \n",
    "            Q += alpha*delta*E\n",
    "            E *= gamma*lambda_\n",
    "            \n",
    "            state = next_state\n",
    "            state_index = next_state_index\n",
    "            action_index = next_action_index\n",
    "        \n",
    "    return Q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action-value table:\n",
      "State      ↑       ↓       ←       →  \n",
      "(0, 0)  -19.97  -19.98  -19.88  -18.65\n",
      "(0, 1)  -18.32  -18.33  -19.20  -17.38\n",
      "(0, 2)  -17.37  -16.45  -18.33  -15.94\n",
      "(0, 3)  -16.25  -15.74  -17.47  -14.53\n",
      "(0, 4)  -14.82  -16.49  -16.08  -13.43\n",
      "(0, 5)  -15.42  -14.41  -15.26  -12.77\n",
      "(0, 6)  -12.60  -13.08  -13.88  -10.48\n",
      "(0, 7)  -11.00  -11.46  -12.69  -10.05\n",
      "(0, 8)   -9.96  -11.71  -11.64   -9.71\n",
      "(0, 9)   -9.04   -7.10  -12.05   -9.24\n",
      "(1, 0)  -19.53  -20.52  -19.76  -17.82\n",
      "(1, 1)  -18.82  -18.73  -19.41  -17.34\n",
      "(1, 2)  -17.18  -16.52  -18.80  -17.22\n",
      "(1, 3)  -16.55  -15.77  -17.30  -13.73\n",
      "(1, 4)  -15.14  -15.82  -15.96  -12.92\n",
      "(1, 5)  -13.02  -13.92  -15.68  -13.62\n",
      "(1, 6)  -12.30  -12.00  -13.20  -10.58\n",
      "(1, 7)  -13.79  -12.18  -12.30   -9.30\n",
      "(1, 8)  -11.28  -11.99  -10.74  -11.41\n",
      "(1, 9)   -9.74   -5.29  -11.53   -8.87\n",
      "(2, 0)  -19.51  -20.59  -19.83  -18.56\n",
      "(2, 1)  -19.37  -19.62  -20.32  -16.22\n",
      "(2, 2)  -18.03  -17.72  -17.64  -15.11\n",
      "(2, 3)  -15.94  -15.86  -17.71  -15.28\n",
      "(2, 4)  -15.54  -14.86  -15.50  -14.36\n",
      "(2, 5)  -13.62  -13.84  -16.06  -11.25\n",
      "(2, 6)  -12.16  -13.00  -13.28   -9.88\n",
      "(2, 7)  -12.29  -11.00  -12.60   -9.54\n",
      "(2, 8)   -9.96  -10.31  -12.72   -7.10\n",
      "(2, 9)   -8.53   -4.26  -10.33   -7.38\n",
      "(3, 0)  -20.42  -18.55  -20.22  -20.19\n",
      "(3, 1)  -19.54  -19.65  -19.98  -18.67\n",
      "(3, 2)  -17.14  -18.06  -19.62  -16.42\n",
      "(3, 3)  -16.26  -16.03  -17.01  -14.96\n",
      "(3, 4)  -15.45  -14.61  -16.41  -12.37\n",
      "(3, 5)  -14.25  -13.62  -14.90  -11.12\n",
      "(3, 6)  -14.25  -14.10  -14.33  -11.10\n",
      "(3, 7)    0.00    0.00    0.00    0.00\n",
      "(3, 8)  -11.03   -9.22  -10.83   -8.30\n",
      "(3, 9)   -6.17   -4.13   -9.03   -6.13\n",
      "(4, 0)  -20.71  -20.76  -20.00  -17.08\n",
      "(4, 1)  -20.54  -18.51  -19.89  -15.75\n",
      "(4, 2)  -17.82  -17.18  -18.79  -14.63\n",
      "(4, 3)  -15.52  -15.77  -17.44  -13.56\n",
      "(4, 4)  -14.98  -15.32  -15.85  -12.56\n",
      "(4, 5)  -15.06  -15.34  -15.15  -13.04\n",
      "(4, 6)    0.00    0.00    0.00    0.00\n",
      "(4, 7)  -10.66   -1.00  -12.40   -9.90\n",
      "(4, 8)   -9.21   -3.01   -1.00   -6.60\n",
      "(4, 9)   -6.67   -6.61   -3.12   -7.18\n",
      "(5, 0)  -20.77  -20.89  -20.10  -18.19\n",
      "(5, 1)  -19.00  -18.80  -19.75  -16.06\n",
      "(5, 2)  -17.42  -18.25  -19.37  -15.18\n",
      "(5, 3)  -16.22  -15.83  -17.50  -14.03\n",
      "(5, 4)  -15.10  -16.14  -16.63  -14.76\n",
      "(5, 5)    0.00    0.00    0.00    0.00\n",
      "(5, 6)    0.00    0.00    0.00    0.00\n",
      "(5, 7)   -9.94   -4.63  -12.76   -8.90\n",
      "(5, 8)  -10.10   -8.63   -8.90   -5.94\n",
      "(5, 9)   -4.47   -8.93   -8.81   -8.91\n",
      "(6, 0)  -20.26  -20.40  -20.21  -19.03\n",
      "(6, 1)  -18.94  -19.24  -19.67  -17.79\n",
      "(6, 2)  -18.22  -17.77  -18.67  -17.08\n",
      "(6, 3)  -16.49  -16.80  -16.95  -16.69\n",
      "(6, 4)    0.00    0.00    0.00    0.00\n",
      "(6, 5)    0.00    0.00    0.00    0.00\n",
      "(6, 6)    0.00    0.00    0.00    0.00\n",
      "(6, 7)    0.00    0.00    0.00    0.00\n",
      "(6, 8)   -3.16   -7.87   -8.77   -7.18\n",
      "(6, 9)   -8.62   -8.54   -6.55   -8.78\n",
      "\n",
      "Resulting greedy policy:\n",
      "→ → → → → → → → → ↓ \n",
      "→ → ↓ → → ↑ → → ← ↓ \n",
      "→ → → → → → → → → ↓ \n",
      "↓ → → → → → → × → ↓ \n",
      "→ → → → → → ↑ ↓ ← ← \n",
      "→ → → → → ↑ ↑ ↓ → ↑ \n",
      "→ → → ↑ ↑ ↑ ↑ ↑ ↑ ← \n",
      "\n"
     ]
    }
   ],
   "source": [
    "q = SarsaLambda(\n",
    "    gw=GW6p5,\n",
    "    maxiters=20000,\n",
    "    policy=eps_greedy_policy,\n",
    "    eps_schedule=lambda a,b: 0.1,\n",
    "    alpha_schedule=constant_alpha_schedule_factory(0.5),\n",
    "    gamma=1,\n",
    "    lambda_=0.1\n",
    ")\n",
    "print_action_value(q, GW6p5)\n",
    "print_resulting_greedy_policy(q, GW6p5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
